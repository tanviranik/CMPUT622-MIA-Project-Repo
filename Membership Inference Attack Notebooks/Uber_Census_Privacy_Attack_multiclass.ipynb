{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "Uber Census Privacy Attack - multiclass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4eDcxydKQLy"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.datasets import cifar100\n",
        "from keras import applications\n",
        "from __future__ import print_function\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.models import load_model #save and load models\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import keras.backend as k"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3s15gFdKQL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc361181-bd45-45bb-b23c-26f0c09a2314"
      },
      "source": [
        "df = pd.read_csv('uber_census_multiclass.csv', encoding = \"ISO-8859-1\", engine='python')\n",
        "df = df[['hour', 'lat', 'long', 'base', 'MedianIncomeByPlaceofBirth', 'MedianIncome', 'AvgPopulation', 'UserGroup']]\n",
        "data = df\n",
        "print(data.shape)\n",
        "print(data.dtypes)\n",
        "df1 = data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9752, 8)\n",
            "hour                            int64\n",
            "lat                           float64\n",
            "long                          float64\n",
            "base                           object\n",
            "MedianIncomeByPlaceofBirth    float64\n",
            "MedianIncome                  float64\n",
            "AvgPopulation                 float64\n",
            "UserGroup                       int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeY_OQ_EKQL3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8a51bb5c-3a10-4646-9534-429a0ac764ec"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hour</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>base</th>\n",
              "      <th>MedianIncomeByPlaceofBirth</th>\n",
              "      <th>MedianIncome</th>\n",
              "      <th>AvgPopulation</th>\n",
              "      <th>UserGroup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59</td>\n",
              "      <td>40.7476</td>\n",
              "      <td>-74.0020</td>\n",
              "      <td>B02617</td>\n",
              "      <td>49364.0</td>\n",
              "      <td>75862.0</td>\n",
              "      <td>10012.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28</td>\n",
              "      <td>40.7385</td>\n",
              "      <td>-73.9733</td>\n",
              "      <td>B02617</td>\n",
              "      <td>51174.0</td>\n",
              "      <td>105170.0</td>\n",
              "      <td>4417.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27</td>\n",
              "      <td>40.7045</td>\n",
              "      <td>-73.7286</td>\n",
              "      <td>B02617</td>\n",
              "      <td>26024.0</td>\n",
              "      <td>68854.0</td>\n",
              "      <td>3654.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>40.6323</td>\n",
              "      <td>-73.7000</td>\n",
              "      <td>B02617</td>\n",
              "      <td>78274.0</td>\n",
              "      <td>211250.0</td>\n",
              "      <td>2732.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>40.9347</td>\n",
              "      <td>-73.9025</td>\n",
              "      <td>B02617</td>\n",
              "      <td>21628.0</td>\n",
              "      <td>27957.0</td>\n",
              "      <td>4379.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   hour      lat     long  ... MedianIncome  AvgPopulation  UserGroup\n",
              "0    59  40.7476 -74.0020  ...      75862.0        10012.0          3\n",
              "1    28  40.7385 -73.9733  ...     105170.0         4417.0          4\n",
              "2    27  40.7045 -73.7286  ...      68854.0         3654.0          3\n",
              "3    20  40.6323 -73.7000  ...     211250.0         2732.0          4\n",
              "4     0  40.9347 -73.9025  ...      27957.0         4379.0          1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAp3ZNob_92j",
        "outputId": "32317709-9320-4ce6-ab33-a17baaba2bfe"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(df1['UserGroup'])\n",
        "encoded_Y = encoder.transform(df1['UserGroup'])\n",
        "print(encoded_Y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "dummy_y.shape\n",
        "print(dummy_y)\n",
        "temp = pd.get_dummies(df1['UserGroup'])\n",
        "dummy_y = temp.values"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 4 3 ... 4 3 3]\n",
            "[[0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcyRcHeaKQL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d9ef63-5463-4a4b-e92a-757357fe4194"
      },
      "source": [
        "names_cloud = data.columns.tolist()\n",
        "print(names_cloud)\n",
        "X = np.array(data[names_cloud])\n",
        "print(X.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hour', 'lat', 'long', 'base', 'MedianIncomeByPlaceofBirth', 'MedianIncome', 'AvgPopulation', 'UserGroup']\n",
            "(9752, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua1QqKNYKQL4"
      },
      "source": [
        "# fig = plt.figure(figsize=(20,20))\n",
        "# cols = 5\n",
        "# rows = (float(data.shape[1]) / cols)\n",
        "# for i, column in enumerate(data.columns):\n",
        "#     a = fig.add_subplot(rows, cols, i + 1)\n",
        "#     a.set_title(column)\n",
        "#     if data.dtypes[column] == np.object:\n",
        "#         data[column].value_counts().plot(kind=\"bar\", axes=a)\n",
        "#     else:\n",
        "#         data[column].hist(axes=a)\n",
        "#         plt.xticks(rotation=\"vertical\")\n",
        "# plt.subplots_adjust(hspace=0.7, wspace=0.2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjKas_fWKQL4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0be378-b115-4e1e-fadd-c829ea57e0e4"
      },
      "source": [
        "y = (data['UserGroup']).values\n",
        "print(pd.value_counts(pd.Series(y)))\n",
        "data.drop('UserGroup',axis=1, inplace =True,)\n",
        "y = dummy_y"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4    3428\n",
            "2    2284\n",
            "3    2200\n",
            "1    1612\n",
            "0     228\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLqfOyCdKQL5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "5fe97ea1-837c-4c0a-d59f-c4c117748d84"
      },
      "source": [
        "categorical_features = data.select_dtypes(include=['object']).columns\n",
        "print(categorical_features)\n",
        "ohc_category = ['base']\n",
        "df_ohc = pd.get_dummies(data, columns = ohc_category)\n",
        "print(df_ohc.shape)\n",
        "df_ohc.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['base'], dtype='object')\n",
            "(9752, 10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hour</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>MedianIncomeByPlaceofBirth</th>\n",
              "      <th>MedianIncome</th>\n",
              "      <th>AvgPopulation</th>\n",
              "      <th>base_B02512</th>\n",
              "      <th>base_B02598</th>\n",
              "      <th>base_B02617</th>\n",
              "      <th>base_B02682</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59</td>\n",
              "      <td>40.7476</td>\n",
              "      <td>-74.0020</td>\n",
              "      <td>49364.0</td>\n",
              "      <td>75862.0</td>\n",
              "      <td>10012.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28</td>\n",
              "      <td>40.7385</td>\n",
              "      <td>-73.9733</td>\n",
              "      <td>51174.0</td>\n",
              "      <td>105170.0</td>\n",
              "      <td>4417.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27</td>\n",
              "      <td>40.7045</td>\n",
              "      <td>-73.7286</td>\n",
              "      <td>26024.0</td>\n",
              "      <td>68854.0</td>\n",
              "      <td>3654.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>40.6323</td>\n",
              "      <td>-73.7000</td>\n",
              "      <td>78274.0</td>\n",
              "      <td>211250.0</td>\n",
              "      <td>2732.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>40.9347</td>\n",
              "      <td>-73.9025</td>\n",
              "      <td>21628.0</td>\n",
              "      <td>27957.0</td>\n",
              "      <td>4379.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   hour      lat     long  ...  base_B02598  base_B02617  base_B02682\n",
              "0    59  40.7476 -74.0020  ...            0            1            0\n",
              "1    28  40.7385 -73.9733  ...            0            1            0\n",
              "2    27  40.7045 -73.7286  ...            0            1            0\n",
              "3    20  40.6323 -73.7000  ...            0            1            0\n",
              "4     0  40.9347 -73.9025  ...            0            1            0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyvXB69LKQL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1988a9-5b07-4279-e691-4e5ed6983a30"
      },
      "source": [
        "names_x = df_ohc.columns.tolist()\n",
        "print(\"Target Variable: UserGroup\")\n",
        "print(\"Predictors: \"+str(names_x))\n",
        "x = np.array(df_ohc[names_x])\n",
        "print(\"Number of data samples : {0:d}\".format(x.shape[0]))\n",
        "print(\"Number of Predictor Features : {0:d}\".format(x.shape[1]))\n",
        "#df_ohc[\"Age\"] = df_ohc[\"Age\"].astype(str).astype(float)\n",
        "# from google.colab import files\n",
        "# df_ohc.to_csv('df.csv')\n",
        "# files.download('df.csv')\n",
        "df_ohc[names_x]\n",
        "print(x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Variable: UserGroup\n",
            "Predictors: ['hour', 'lat', 'long', 'MedianIncomeByPlaceofBirth', 'MedianIncome', 'AvgPopulation', 'base_B02512', 'base_B02598', 'base_B02617', 'base_B02682']\n",
            "Number of data samples : 9752\n",
            "Number of Predictor Features : 10\n",
            "[[ 59.      40.7476 -74.002  ...   0.       1.       0.    ]\n",
            " [ 28.      40.7385 -73.9733 ...   0.       1.       0.    ]\n",
            " [ 27.      40.7045 -73.7286 ...   0.       1.       0.    ]\n",
            " ...\n",
            " [ 42.      40.6607 -73.9894 ...   1.       0.       0.    ]\n",
            " [ 32.      40.7729 -73.9213 ...   0.       1.       0.    ]\n",
            " [ 48.      40.6197 -73.9664 ...   0.       1.       0.    ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDL1Zx6oLDqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6220a0f7-8ad4-49d6-8a87-ad9ca01c9a64"
      },
      "source": [
        "df_ohc.dtypes"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "hour                            int64\n",
              "lat                           float64\n",
              "long                          float64\n",
              "MedianIncomeByPlaceofBirth    float64\n",
              "MedianIncome                  float64\n",
              "AvgPopulation                 float64\n",
              "base_B02512                     uint8\n",
              "base_B02598                     uint8\n",
              "base_B02617                     uint8\n",
              "base_B02682                     uint8\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaiuLVXZKQL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1a6f99-3655-43b1-d601-138193db1cf4"
      },
      "source": [
        "x = x.astype('float32')\n",
        "print(x)\n",
        "x = x/255\n",
        "print(x)\n",
        "batch_size = 64 #upto us\n",
        "epochs = 200\n",
        "lrate = 0.001\n",
        "decay = 1e-7 \n",
        "data_size = 2500\n",
        "ns = 10 #number of shadow models for one data_size\n",
        "nh = 8 #number of hidden layers\n",
        "nout = 1\n",
        "seed = 9\n",
        "np.random.seed(seed)\n",
        "sh = np.arange(x.shape[0])\n",
        "print(sh)\n",
        "np.random.shuffle(sh)\n",
        "target_rep = np.zeros((1,x.shape[0]))\n",
        "print(target_rep)\n",
        "target_rep[0,:] = sh\n",
        "print(sh)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 59.      40.7476 -74.002  ...   0.       1.       0.    ]\n",
            " [ 28.      40.7385 -73.9733 ...   0.       1.       0.    ]\n",
            " [ 27.      40.7045 -73.7286 ...   0.       1.       0.    ]\n",
            " ...\n",
            " [ 42.      40.6607 -73.9894 ...   1.       0.       0.    ]\n",
            " [ 32.      40.7729 -73.9213 ...   0.       1.       0.    ]\n",
            " [ 48.      40.6197 -73.9664 ...   0.       1.       0.    ]]\n",
            "[[ 0.23137255  0.15979451 -0.29020393 ...  0.          0.00392157\n",
            "   0.        ]\n",
            " [ 0.10980392  0.15975882 -0.29009137 ...  0.          0.00392157\n",
            "   0.        ]\n",
            " [ 0.10588235  0.15962549 -0.28913176 ...  0.          0.00392157\n",
            "   0.        ]\n",
            " ...\n",
            " [ 0.16470589  0.15945373 -0.29015452 ...  0.00392157  0.\n",
            "   0.        ]\n",
            " [ 0.1254902   0.15989372 -0.28988746 ...  0.          0.00392157\n",
            "   0.        ]\n",
            " [ 0.1882353   0.15929295 -0.2900643  ...  0.          0.00392157\n",
            "   0.        ]]\n",
            "[   0    1    2 ... 9749 9750 9751]\n",
            "[[0. 0. 0. ... 0. 0. 0.]]\n",
            "[   8 5849 3725 ... 6782 4444 8574]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hop0ijufKQL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "affd3a29-2bf6-4292-a2c9-76e6798745f1"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "k.clear_session()\n",
        "xtr_target = x[sh[:data_size]]\n",
        "ytr_target = y[sh[:data_size]]\n",
        "xts_target = x[sh[data_size:data_size*2]]\n",
        "yts_target = y[sh[data_size:2*data_size]]\n",
        "print(xts_target.shape, yts_target)\n",
        "shadow_rep = np.zeros((20,x.shape[0]-2*data_size))\n",
        "sh1 = sh[2*data_size:]\n",
        "xtr_att = np.zeros((2*data_size*ns,1))\n",
        "ytr_att = np.zeros((2*data_size*ns,1))\n",
        "xtr_att_truelabels = np.zeros((2*data_size*ns,))\n",
        "model_target = Sequential()\n",
        "model_target.add(Dense(nh, input_shape =(x.shape[1],), activation='relu', name = 'hidden'))\n",
        "model_target.add(Dense(5, activation='softmax', name = 'output'))\n",
        "opt = Adam(lr=lrate, decay=decay) \n",
        "model_target.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "print(model_target.summary())\n",
        "hist_target = model_target.fit(xtr_target, ytr_target,\n",
        "                  batch_size = batch_size,\n",
        "                  epochs = epochs,\n",
        "                  validation_data=(xts_target, yts_target), shuffle=True, verbose=0)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2500, 10) [[0 1 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " ...\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 8)                 88        \n",
            "                                                                 \n",
            " output (Dense)              (None, 5)                 45        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133\n",
            "Trainable params: 133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VmVhGnsCNhT",
        "outputId": "5743124c-712d-435f-939c-91a0be9903a3"
      },
      "source": [
        "print(xtr_target.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2500, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifZNvv4JUaX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1370fca-4759-4a38-a47c-772ff081d696"
      },
      "source": [
        "print('\\n\\nFor target model with training datasize = %d'%data_size)\n",
        "print('Training accuracy = ', hist_target.history['accuracy'][-1])\n",
        "print('Validation accuracy = ', hist_target.history['val_accuracy'][-1])\n",
        "model_target_name = 'UBER_CENSUS_target_'+str(data_size)+'.h5'\n",
        "model_target.save(model_target_name)\n",
        "ytemp_tr_target = model_target.predict(xtr_target)\n",
        "ytemp_ts_target = model_target.predict(xts_target)\n",
        "xts_att = np.vstack((ytemp_tr_target,ytemp_ts_target))\n",
        "yts_att = np.zeros((2*data_size,1))\n",
        "yts_att[data_size:2*data_size] = 1  \n",
        "xts_att_truelabels = np.vstack((ytr_target,yts_target))\n",
        "xts_att_dict = {'xts_att':xts_att,'yts_att':yts_att,'xts_att_truelabels':xts_att_truelabels}\n",
        "fname = './att_test_data_'+str(data_size)\n",
        "np.save(fname,xts_att_dict)\n",
        "datafile = './UBER_CENSUS_target_'+str(data_size)\n",
        "np.save(datafile,target_rep)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "For target model with training datasize = 2500\n",
            "Training accuracy =  0.8460000157356262\n",
            "Validation accuracy =  0.8335999846458435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V16OIzm_q_O7"
      },
      "source": [
        "**IBM diffprivlib**\n",
        "\n",
        "Only GaussianNB is used, and we implored the *IBM diffprivlib* library to implement privacy mechanisms for our multi-class classifier model trained on 9 features with five classes to predict from. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "U6UV53X4sVUS",
        "outputId": "f3c89c25-91cc-4b37-aa0e-263dfdc837fc"
      },
      "source": [
        "!pip install diffprivlib"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffprivlib\n",
            "  Downloading diffprivlib-0.5.0.tar.gz (87 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 20 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 30 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 40 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 51 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 61 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 71 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 81 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 87 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from diffprivlib) (1.19.5)\n",
            "Requirement already satisfied: setuptools>=49.0.0 in /usr/local/lib/python3.7/dist-packages (from diffprivlib) (57.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from diffprivlib) (1.0.1)\n",
            "Collecting scipy>=1.5.0\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from diffprivlib) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->diffprivlib) (3.0.0)\n",
            "Building wheels for collected packages: diffprivlib\n",
            "  Building wheel for diffprivlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffprivlib: filename=diffprivlib-0.5.0-py3-none-any.whl size=162302 sha256=4969836126c7e3b38059ab34038f8359abe4cc822d3a13211d9a82f0bc8da35d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/06/66/53eecc576e61a914f03ad5caee627823eb857225cb84aeb6d2\n",
            "Successfully built diffprivlib\n",
            "Installing collected packages: scipy, diffprivlib\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed diffprivlib-0.5.0 scipy-1.7.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "scipy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MSoifBvq-QS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "outputId": "110f8404-ab12-439a-c643-26ddfba34aa8"
      },
      "source": [
        "from diffprivlib.models import GaussianNB\n",
        "\n",
        "epsilons = np.logspace(-2, 2, 50)\n",
        "bounds = ([4.3, 2.0, 1.1, 0.1], [7.9, 4.4, 6.9, 2.5])\n",
        "accuracy = list()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-243637fbf93c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffprivlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepsilons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/diffprivlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \"\"\"\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffprivlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmechanisms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffprivlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffprivlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffprivlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccountant\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBudgetAccountant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/diffprivlib/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \"\"\"\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffprivlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffprivlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_means\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffprivlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffprivlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/diffprivlib/models/k_means.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msk_cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffprivlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccountant\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBudgetAccountant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/cluster/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_spectral\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspectral_clustering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpectralClustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_mean_shift\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_shift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMeanShift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimate_bandwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_bin_seeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_affinity_propagation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maffinity_propagation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAffinityPropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_spectral.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpairwise_kernels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkneighbors_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspectral_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_kmeans\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mk_means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/manifold/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_mds\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmacof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_spectral_embedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpectralEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspectral_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_t_sne\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrustworthiness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m __all__ = [\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# mypy error: Module 'sklearn.manifold' has no attribute '_barnes_hut_tsne'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_barnes_hut_tsne\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/manifold/_barnes_hut_tsne.pyx\u001b[0m in \u001b[0;36minit sklearn.manifold._barnes_hut_tsne\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msklearn/neighbors/_quad_tree.pyx\u001b[0m in \u001b[0;36minit sklearn.neighbors._quad_tree\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseDecisionTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_criterion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCriterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_splitter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDepthFirstTreeBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/tree/_criterion.pyx\u001b[0m in \u001b[0;36minit sklearn.tree._criterion\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcython_special.pyx\u001b[0m in \u001b[0;36minit scipy.special.cython_special\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: scipy.special._ufuncs_cxx does not export expected C variable _export_expit",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytr = []\n",
        "yts = []\n",
        "for i in range(len(ytr_target)):\n",
        "  index = np.nonzero(ytr_target[i])\n",
        "  ytr.append(index[0][0]+1)\n",
        "\n",
        "for i in range(len(yts_target)):\n",
        "  index = np.nonzero(yts_target[i])\n",
        "  yts.append(index[0][0]+1)\n",
        "\n",
        "ytr_target_priv = np.asarray(ytr)\n",
        "yts_target_priv = np.asarray(yts)\n",
        "print(ytr_target_priv.shape)"
      ],
      "metadata": {
        "id": "6WKYFOzzXo3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV-qlwOsuGOC"
      },
      "source": [
        "**Training Differentially Private Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQwV1S9luO-B"
      },
      "source": [
        "#Training & Calculating for Different Epsilons\n",
        "\n",
        "for epsilon in epsilons:\n",
        "  diffpriv_model = GaussianNB(epsilon=epsilon)\n",
        "  diffpriv_model.fit(xtr_target, ytr_target_priv)\n",
        "  #accuracy on test data for the model and appending them in a list\n",
        "  accuracy.append(diffpriv_model.score(xts_target, yts_target_priv))\n",
        "\n",
        "print(accuracy)\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the Accuracy vs epsilons for our multi-class classifier\n",
        "plt.semilogx(epsilons, accuracy)\n",
        "plt.title(\"Differentially private Naive Bayes accuracy\")\n",
        "plt.xlabel(\"epsilon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u03bCTgeuWnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shadow models"
      ],
      "metadata": {
        "id": "6LTxRByruj97"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdesgvSLKQL8"
      },
      "source": [
        "for i in np.arange(ns):\n",
        "    np.random.shuffle(sh1)\n",
        "    shadow_rep[i,:] = sh1\n",
        "    xtr_shadow = x[sh1[:data_size]]\n",
        "    ytr_shadow = y[sh1[:data_size]]\n",
        "    xts_shadow = x[sh1[data_size:2*data_size]]\n",
        "    yts_shadow = y[sh1[data_size:2*data_size]]\n",
        "    model_shadow = Sequential()\n",
        "    model_shadow.add(Dense(nh, input_shape =(x.shape[1],), activation='relu', name = 'hidden'))\n",
        "    model_shadow.add(Dense(5, activation='softmax', name = 'output'))\n",
        "    opt = Adam(learning_rate=lrate, decay=decay) \n",
        "    model_shadow.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    if i == 0:\n",
        "        print(\"Shadow Model Summary\")\n",
        "        print(model_shadow.summary())\n",
        "    hist_shadow = model_shadow.fit(xtr_shadow, ytr_shadow,\n",
        "                  batch_size = batch_size,\n",
        "                  epochs = epochs,\n",
        "                  validation_data=(xts_shadow, yts_shadow), shuffle=True, verbose=0)\n",
        "    print(\"Shadow model no: %d\"%i)\n",
        "    print('\\n\\nFor shadow model with training datasize = %d'%data_size)\n",
        "    print('Training accuracy = ', hist_shadow.history['accuracy'][-1])\n",
        "    print('Validation accuracy = ', hist_shadow.history['val_accuracy'][-1])\n",
        "    ytemp11 = model_shadow.predict(xtr_shadow)\n",
        "    t1 = [[i] for i in np.argmax(ytemp11, axis=1)]\n",
        "    \n",
        "    ytemp22 = model_shadow.predict(xts_shadow)\n",
        "    t2 = [[i] for i in np.argmax(ytemp22, axis=1)]\n",
        "\n",
        "\n",
        "    model_shadow_name = 'UBER_CENSUS_shadow_'+str(data_size)+'_'+str(i)+'.h5'\n",
        "    print(model_shadow_name)\n",
        "    model_shadow.save(model_shadow_name)    \n",
        "    \n",
        "    print('****')\n",
        "    #print(np.vstack((ytemp11,ytemp22)))\n",
        "    # original_1 = np.argmax(ytemp11, axis=1) \n",
        "    # original_2 = np.argmax(ytemp22, axis=1) \n",
        "    # prediction_ = np.argmax(ytemp11, axis = 1)\n",
        "    # print(prediction_)\n",
        "    # print(ytemp11)\n",
        "    # print(original_2)\n",
        "    xtr_att[i*2*data_size:(i+1)*2*data_size] = np.vstack((t1, t2))\n",
        "    ytr_att[((i*2)+1)*data_size:(i+1)*2*data_size] = 1\n",
        "\n",
        "    #t3 = [[i] for i in np.argmax(ytr_shadow, axis=1)]\n",
        "    #t4 = [[i] for i in np.argmax(yts_shadow, axis=1)]\n",
        "\n",
        "    #xtr_att_truelabels[i*2*data_size:(i+1)*2*data_size] = np.hstack((t3,t4))\n",
        "datafile = './UBER_CENSUS_shadow_'+str(data_size)\n",
        "np.save(datafile,shadow_rep)\n",
        "#xtr_att_dict = {'xtr_att':xtr_att,'ytr_att':ytr_att,'xtr_att_truelabels':xtr_att_truelabels}\n",
        "xtr_att_dict = {'xtr_att':xtr_att,'ytr_att':ytr_att}\n",
        "fname = './att_train_data_'+str(data_size)\n",
        "np.save(fname,xtr_att_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmi7z4PIyZaQ"
      },
      "source": [
        "# t = [[i] for i in np.argmax(ytemp11, axis=1)]\n",
        "# print(np.array(t))\n",
        "print(xtr_att, xtr_att.shape)\n",
        "print(ytr_att, ytr_att.shape)\n",
        "\n",
        "print('****')\n",
        "# print(xts_att)\n",
        "xts_att_ = [[i] for i in np.argmax(xts_att, axis=1)]\n",
        "t5 = np.array(xts_att_)\n",
        "print(t5, t5.shape)\n",
        "print(yts_att, yts_att.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attack Models"
      ],
      "metadata": {
        "id": "-X9DQ_7uu0yW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvHRDvhLKQL9"
      },
      "source": [
        "model_attack = Sequential()\n",
        "model_attack.add(Dense(nh, input_shape = (xtr_att.shape[1],), activation='sigmoid', name = 'hidden'))\n",
        "model_attack.add(Dense(1, activation='sigmoid', name = 'output'))\n",
        "opt = Adam(learning_rate=lrate, decay=decay) \n",
        "model_attack.compile(loss='binary_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "print(\"Attack Model Summary\")\n",
        "print(model_attack.summary())\n",
        "hist_attack = model_attack.fit(xtr_att, ytr_att,\n",
        "                  batch_size = batch_size,\n",
        "                  epochs = epochs,\n",
        "                  validation_data=(t5, yts_att), shuffle=True, verbose=0)\n",
        "print('\\n\\nFor attack model with training datasize = %d'%xtr_att.shape[0])\n",
        "print('Training accuracy = ', hist_shadow.history['accuracy'][-1])\n",
        "print('Validation accuracy = ', hist_shadow.history['val_accuracy'][-1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}